{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# tqdm for notebooks\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807f09",
   "metadata": {},
   "source": [
    "# create folder for each dataset first    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09845339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    # if no such directory, create one\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7083bf5",
   "metadata": {},
   "source": [
    "# qvh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/QVHighlights'\n",
    "ann_root = \"../../data/annotations\"\n",
    "train_path = ann_root + '/highlight_train_release.jsonl'\n",
    "val_path = ann_root + '/highlight_val_release.jsonl'\n",
    "test_path = ann_root + '/highlight_test_release.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d681ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_QVH(data, relative_time=False, save_float=False, is_test=False):\n",
    "    out = []\n",
    "    for d in data:\n",
    "        sample = {}\n",
    "        sample['video'] = d['vid']\n",
    "        sample['qid'] = 'QVHighlight_' + str(d['qid'])\n",
    "        sample['query'] = d['query']\n",
    "        duration = d['duration']\n",
    "        sample['duration'] = duration\n",
    "\n",
    "        if not is_test:\n",
    "            windows = d['relevant_windows']\n",
    "            if relative_time:\n",
    "                relative_time_windows = []\n",
    "                for window in windows:\n",
    "                    start = window[0] / duration\n",
    "                    end = window[1] / duration\n",
    "\n",
    "                    if save_float:\n",
    "                        relative_time_windows.append([round(start, 2), round(end, 2)])\n",
    "                    else:\n",
    "                        relative_time_windows.append([int(round(start, 2) * 100), int(round(end, 2) * 100)])\n",
    "                sample['relevant_windows'] = relative_time_windows\n",
    "            else:\n",
    "                sample['relevant_windows'] = windows\n",
    "        else:\n",
    "            sample['relevant_windows'] = [[0, 150]] # dummy value\n",
    "\n",
    "        out.append(sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_QVH(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_QVH(val, relative_time=relative_time, save_float=save_float)\n",
    "new_test = process_QVH(test, relative_time=relative_time, save_float=save_float, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9754fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float_dummy.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float_dummy.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_dummy.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_dummy.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151075f",
   "metadata": {},
   "source": [
    "# Charades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from /pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_v1_train.csv\n",
    "train_df = pd.read_csv('/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_original/Charades_v1_train.csv', delimiter=',')\n",
    "test_df = pd.read_csv('/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_original/Charades_v1_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique ids\n",
    "train_ids = train_df[\"id\"].unique()\n",
    "print(len(train_ids))\n",
    "\n",
    "# randomly select 800 ids for validation\n",
    "random.seed(42)\n",
    "random.shuffle(train_ids)\n",
    "\n",
    "val_ids = train_ids[:800]\n",
    "train_ids = train_ids[800:]\n",
    "\n",
    "len(val_ids), len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = '/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/Charades/Charades_STA'\n",
    "train_path = ann_root + '/train.txt'\n",
    "test_path = ann_root + '/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_charades_STA(data_path, df, video_ids=None, relative_time=False, save_float=False):\n",
    "    # read txt and put each line into new element in list\n",
    "    with open(data_path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    out = []\n",
    "\n",
    "    for s in content:\n",
    "        # format \"id start end##query\"\n",
    "        s = s.split('##') # -> [id start end, query]\n",
    "        query = s[1] # -> query\n",
    "        s = s[0] # -> id start end\n",
    "        s = s.split(' ') # -> [[id], [start], [end]]\n",
    "        id = s[0] # -> id\n",
    "\n",
    "        if video_ids is not None and id not in video_ids:\n",
    "            continue\n",
    "        \n",
    "        # get meta data from df using id\n",
    "        # get row with id == id\n",
    "        row = df.loc[df[\"id\"] == id]\n",
    "        values = row.values[0]\n",
    "\n",
    "        # get duration\n",
    "        duration = values[10]\n",
    "\n",
    "        # convert to float\n",
    "        s[1] = float(s[1])\n",
    "        s[2] = float(s[2])\n",
    "        if s[2] > duration:\n",
    "            s[2] = duration\n",
    "\n",
    "        if relative_time:\n",
    "            # convert to relative time\n",
    "            s[1] = s[1] / duration\n",
    "            s[2] = s[2] / duration\n",
    "\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [round(s[1], 2), round(s[2], 2)] # -> [start, end]\n",
    "                assert window[0] >= 0 and window[1] <= 1\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [int(s[1] * 100), int(s[2] * 100)]\n",
    "                assert window[0] >= 0 and window[1] <= 100\n",
    "        else:\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [float(s[1]), float(s[2])] # -> [start, end]\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [round(float(s[1])), round(float(s[2]))]\n",
    "\n",
    "        # get objects\n",
    "        objects = values[7]\n",
    "        # only split if objects is not nan or contains ; (which means multiple objects)\n",
    "        try:\n",
    "            objects = objects.split(';')\n",
    "        except:\n",
    "            print('no objects: ', objects, ' for id: ', id)\n",
    "            objects = []\n",
    "\n",
    "        out.append(\n",
    "            {\n",
    "                'id': id,\n",
    "                'query': query,\n",
    "                'window': [window],\n",
    "                'duration': duration,\n",
    "                'objects': objects\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, train_ids, relative_time=relative_time, save_float=save_float)\n",
    "val = process_charades_STA(train_path, train_df, val_ids, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978bc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/new_train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/new_val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72299f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing without the custom data slipt, i.e. having only the original train and test split\n",
    "\n",
    "save_float = True\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(train_path, train_df, None, relative_time=relative_time, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['id']\n",
    "    qa_dict['qid'] = 'Charades-STA_' + str(qa['id'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    qa_dict['duration'] = qa['duration']\n",
    "    qa_dict['relevant_windows'] = qa['window']\n",
    "    qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b225d55",
   "metadata": {},
   "source": [
    "# TACoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "# import VideoFileClip\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808905a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/\"\n",
    "directory_avi = os.path.join(base_path, \"videos\")\n",
    "directory_mp4 = os.path.join(base_path, \"TACoS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ef371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert avi to mp4 \n",
    "\n",
    "def convert_avi_to_mp4(filename, avi_path, target_path):\n",
    "    os.system('ffmpeg -i {} {}'.format(\n",
    "        os.path.join(avi_path, filename),\n",
    "        os.path.join(target_path, filename.replace('.avi', '.mp4'))\n",
    "    ))\n",
    "\n",
    "# get all avi files\n",
    "avi_files = glob(os.path.join(directory_avi, \"*.avi\"))\n",
    "avi_files = [os.path.basename(f) for f in avi_files]\n",
    "\n",
    "# convert all avi files to mp4\n",
    "for avi_file in avi_files:\n",
    "    # if file already exists, skip\n",
    "    if not os.path.exists(os.path.join(directory_mp4, avi_file.replace('.avi', '.mp4'))):\n",
    "        convert_avi_to_mp4(avi_file, directory_avi, directory_mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a987d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downscale resolution to 224x224\n",
    "target_path = os.path.join(directory_mp4, \"res_224\")\n",
    "\n",
    "def downscale_resolution(filename, source_path, target_path):\n",
    "    os.system('ffmpeg -i {} -vf scale=224:224 {}'.format(\n",
    "        os.path.join(source_path, filename),\n",
    "        os.path.join(target_path, filename)\n",
    "    ))\n",
    "\n",
    "# get all mp4 files\n",
    "mp4_files = glob(os.path.join(directory_mp4, \"*.mp4\"))\n",
    "mp4_files = [os.path.basename(f) for f in mp4_files]\n",
    "\n",
    "# downscale all mp4 files to 224x224\n",
    "for mp4_file in mp4_files:\n",
    "    # if file already exists, skip\n",
    "    if not os.path.exists(os.path.join(target_path, mp4_file)):\n",
    "        downscale_resolution(mp4_file, directory_mp4, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/TACoS\"\n",
    "train_path = os.path.join(ann_root, \"train.jsonl\")\n",
    "val_path = os.path.join(ann_root, \"val.jsonl\")\n",
    "test_path = os.path.join(ann_root, \"test.jsonl\")\n",
    "\n",
    "\n",
    "video_path = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/raw/TACoS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53724b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read jsonl\n",
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)\n",
    "\n",
    "# show length of each split\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20796021",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = True\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "\n",
    "    start, end = qa['relevant_windows'][0]\n",
    "    if relative_time:\n",
    "        # convert to relative time\n",
    "        start = start / qa['duration']\n",
    "        end = end / qa['duration']\n",
    "\n",
    "        if save_float:\n",
    "            # For float conversion\n",
    "            window = [round(start, 2), round(end, 2)] # -> [start, end]\n",
    "            assert window[0] >= 0 and window[1] <= 1\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "        else:\n",
    "            # For int conversion -> round to nearest int\n",
    "            window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "            assert window[0] >= 0 and window[1] <= 100\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "    else:\n",
    "        if save_float:\n",
    "            # For float conversion\n",
    "            window = [float(start), float(end)] # -> [start, end]\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "        else:\n",
    "            # For int conversion -> round to nearest int\n",
    "            window = [round(float(start)), round(float(end))]\n",
    "            qa_dict['relevant_windows'] = [window]\n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    # round relevant windows to 2 decimal places\n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "    if save_float:\n",
    "        qa_dict['relevant_windows'] = [[float(round(x, 2)) for x in qa['relevant_windows'][0]]]\n",
    "    else:\n",
    "        qa_dict['relevant_windows'] = [[int(round(x)) for x in qa['relevant_windows'][0]]]\n",
    "    \n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict['video'] = qa['vid']\n",
    "    qa_dict['qid'] = 'TACoS_' + str(qa['qid'])\n",
    "    qa_dict['query'] = qa['query']\n",
    "    # round duration to 2 decimal places\n",
    "    qa_dict['duration'] = round(qa['duration'], 2)\n",
    "    \n",
    "    # round relevant windows to 2 decimal places\n",
    "    assert len(qa['relevant_windows']) == 1\n",
    "    if save_float:\n",
    "        qa_dict['relevant_windows'] = [[float(round(x, 2)) for x in qa['relevant_windows'][0]]]\n",
    "    else:\n",
    "        qa_dict['relevant_windows'] = [[int(round(x)) for x in qa['relevant_windows'][0]]]\n",
    "    \n",
    "    # qa_dict['objects'] = qa['objects']\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b041cad",
   "metadata": {},
   "source": [
    "# ActivityNet Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920332",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/ActivityNet\"\n",
    "train_path = os.path.join(ann_root, \"train.json\")\n",
    "val_path = os.path.join(ann_root, \"val_1.json\")\n",
    "test_path = os.path.join(ann_root, \"val_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_json(train_path)\n",
    "val = load_json(val_path)\n",
    "test = load_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet(data, relative_time=False, save_float=False):\n",
    "    out = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        duration = sample['duration']\n",
    "        sentences = sample['sentences']\n",
    "        timestamps = sample['timestamps']\n",
    "        for j, (start, end) in enumerate(timestamps):\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "\n",
    "            new_sample = {\n",
    "                'video': video_id,\n",
    "                'qid': f'ActivityNet_{video_id}_{j}',\n",
    "                'query': sentences[j],\n",
    "                'duration': duration,\n",
    "                'relevant_windows': [window]\n",
    "            }\n",
    "\n",
    "            out.append(new_sample)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_activitynet(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_activitynet(val, save_float=save_float)\n",
    "new_test = process_activitynet(test, save_float=save_float)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(new_train, ann_root + '/lavis/train.json')\n",
    "    save_json(new_val, ann_root + '/lavis/val.json')\n",
    "    save_json(new_test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e7648",
   "metadata": {},
   "source": [
    "# ANet TAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832227fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"/pfss/mlde/workspaces/mlde_wsp_Rohrbach/data/annotations/ActivityNet_TAL\"\n",
    "data = load_json(ann_root + '/anet_tal.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_all = [\n",
    "    'a photo of {}.',\n",
    "    'a photo of a person {}.',\n",
    "    'a photo of a person using {}.',\n",
    "    'a photo of a person doing {}.',\n",
    "    'a photo of a person during {}.',\n",
    "    'a photo of a person performing {}.',\n",
    "    'a photo of a person practicing {}.',\n",
    "    'a video of {}.',\n",
    "    'a video of a person {}.',\n",
    "    'a video of a person using {}.',\n",
    "    'a video of a person doing {}.',\n",
    "    'a video of a person during {}.',\n",
    "    'a video of a person performing {}.',\n",
    "    'a video of a person practicing {}.',\n",
    "    'a example of {}.',\n",
    "    'a example of a person {}.',\n",
    "    'a example of a person using {}.',\n",
    "    'a example of a person doing {}.',\n",
    "    'a example of a person during {}.',\n",
    "    'a example of a person performing {}.',\n",
    "    'a example of a person practicing {}.',\n",
    "    'a demonstration of {}.',\n",
    "    'a demonstration of a person {}.',\n",
    "    'a demonstration of a person using {}.',\n",
    "    'a demonstration of a person doing {}.',\n",
    "    'a demonstration of a person during {}.',\n",
    "    'a demonstration of a person performing {}.',\n",
    "    'a demonstration of a person practicing {}.',\n",
    "]\n",
    "\n",
    "templates_video = [\n",
    "    'a video of {}.',\n",
    "    'a video of a person {}.',\n",
    "    'a video of a person using {}.',\n",
    "    'a video of a person doing {}.',\n",
    "    'a video of a person during {}.',\n",
    "    'a video of a person performing {}.',\n",
    "    'a video of a person practicing {}.',\n",
    "    'a example of {}.',\n",
    "    'a example of a person {}.',\n",
    "    'a example of a person using {}.',\n",
    "    'a example of a person doing {}.',\n",
    "    'a example of a person during {}.',\n",
    "    'a example of a person performing {}.',\n",
    "    'a example of a person practicing {}.',\n",
    "    'a demonstration of {}.',\n",
    "    'a demonstration of a person {}.',\n",
    "    'a demonstration of a person using {}.',\n",
    "    'a demonstration of a person doing {}.',\n",
    "    'a demonstration of a person during {}.',\n",
    "    'a demonstration of a person performing {}.',\n",
    "    'a demonstration of a person practicing {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82913c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet_tal(data, relative_time=False, save_float=False):\n",
    "    out_train = []\n",
    "    out_val = []\n",
    "    out_test = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        video_id = \"v_\" + video_id\n",
    "        duration = sample['duration']\n",
    "        split = sample['subset']\n",
    "        annotations = sample['annotations']\n",
    "        windows = []\n",
    "        for ann in annotations:\n",
    "            start = ann['segment'][0]\n",
    "            end = ann['segment'][1]\n",
    "\n",
    "            # label will always be the same for all annotations/ windows\n",
    "            label = ann['label']\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "            \n",
    "            windows.append(window)\n",
    "\n",
    "        # get one example of the template and insert the label in lower case\n",
    "        query = random.choice(templates_video).format(label.lower())\n",
    "\n",
    "        new_sample = {\n",
    "            'video': video_id,\n",
    "            'qid': f'ActivityNet_{video_id}_0',\n",
    "            'query': query,\n",
    "            'duration': duration,\n",
    "            'relevant_windows': windows\n",
    "        }\n",
    "\n",
    "        if split == 'training':\n",
    "            out_train.append(new_sample)\n",
    "        elif split == 'validation':\n",
    "            out_val.append(new_sample)\n",
    "        elif split == 'testing':\n",
    "            out_test.append(new_sample)\n",
    "    \n",
    "    return out_train, out_val, out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "train, val, test = process_activitynet_tal(data[\"database\"], relative_time=relative_time, save_float=save_float)\n",
    "\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f110155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_relative_float.json')\n",
    "    save_json(val, ann_root + '/lavis/val_relative_float.json')\n",
    "    save_json(test, ann_root + '/lavis/test_relative_float.json')\n",
    "elif save_float and not relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_float.json')\n",
    "    save_json(val, ann_root + '/lavis/val_float.json')\n",
    "    save_json(test, ann_root + '/lavis/test_float.json')\n",
    "elif not save_float and relative_time:\n",
    "    save_json(train, ann_root + '/lavis/train_relative.json')\n",
    "    save_json(val, ann_root + '/lavis/val_relative.json')\n",
    "    save_json(test, ann_root + '/lavis/test_relative.json')\n",
    "else:\n",
    "    save_json(train, ann_root + '/lavis/train.json')\n",
    "    save_json(val, ann_root + '/lavis/val.json')\n",
    "    save_json(test, ann_root + '/lavis/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5490c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
